人工知能学会研究会資料
SIG-FIN-024

テキストマイニングを利用したテーマに関連する上場企業検索ツールの開発

Development of Search Tool for Listed Company Related to Themes
Using Text Mining

平野正徳* 坂地泰紀! 木村逢子? 和泉潔! 松島裕康! 長尾慎太郎? 加藤性雄3
「 東京大学 大学院工学系研究科
+ School of Engineering、 The Umivensity of Tokyo
* 大和証券投資信託委託株式会社 調査部



1 はじめに

近年日本において 個人投資家の数が増えている。
個人投資家の増加に対店し。個人投資家をサポートす
るさまざまな技術が開発されている. ニュース記事の
中から自動的に景気動向を示す表現を抜き出す手法
や, 上場企業が公開する。 共通形式の決算
遅報である決算短信の中から自動的に業績関連文を
取り出す手法, 金融テキストのセンチ
メントを可視化する解航可能なテキストマイニング
などがあげられる

日本の個人投資家の間では, 特に投次信託と呼ばれ
る, 投資家から集めた資金で投資信託会社などが資金
信用をして。 成果を投資家に選元する金融商品が人気
がある.似たような金融商品の一種として。 世界中で
取引されている Exchange Traded Funds (ETF) が有
名であるが, 投資信託と FTF は大きく異なる、ETF
は一般に, それぞれの ETF を構成する構成銘柄の比率
は固定されている. 一方で, 投資信託は, 投資信託を
管理している金融機関や投資信託会社などが, 動的
構成銘柄やその構成比率を変更させている

投資信託の中には, テーマ型投資信託 (テーマ型ファ
ンド) と呼ばれる投資信託が存在する. 特にテーマ型投
資信託は日本の投資家に人気があり, 人工知能 (AI) ,
ロボティクス, 健康など特定の分野を投資先として選
んだものとなっている. これらのテーマ弄投資信託は,
テーマに関連する株式への投資を通じて, テーマの感
り上がりに応じた収益を得ることを目指している.
投資信託会社は, さまざまな種類のファンドを立ち
上げ, 管理・運用をしている. 特に, 投資家を引き付
けるためには, さまざまな種類のテーマ型ファンドを
売り出すことが重要であるととも    ーマの盛り上
がりに対して, 適切なタイミングでファンドを売り出
していくことが重要である.

テーマ型ファンドの開発には多くの課題がある. テー
て弄投資信託を作成するために, 投資信託会社は,売
れそうな投資信託のテーマを探し, さらに, テーマに関連
する銘柄を探さなければならない. 加えて, その
中から運用において優秀な銘柄を選択してポートフォ
リオを作成しなけれぼならない. 関連する銘柄を探す
ことは, 投資信託を運用するファンドマネージャー
とって, 時間的に多大な負担でありさらに,人手で行
うと, 本当はテーマに関連のある銘柄を見落としてし
まう可能性もある. また, ファンドマネージャーは必
ずしもテーマに関して詳しいわけではなく, そういっ|
マを取り扱う場合には, 事前のリサーチを行う
で対応をしているが, グローバルな投資信託 つ
まり, 海外の銘柄を含むようなファンドの場合 全て
の銘柄をカバーすることはほぼ不可能である. そこ
ファンドマ    ャーの負担を軽減し。
する銘柄を見落としなく抽出するため|
を自動化することが必要である

近年。 様々な技術が発展してきている 特6
ストマイニングやビッグデータなどの技術は。
野に応用可能であると考えられる
テキストマイニングに若目して, 自然
た, 関連銘柄抽出手法を提案する。

テキ
の分

2 先行研究

テーマ弄投資信託における, ファンドマネ
をサ:    トするようなシステムの樽築は, 現在の日本
市場においてはまだまだ先進的な取り組みであり, 新
規必の商いタスクである。 そのため。 ここでは, 関連
する分野における先行研究について述べる.

まず, 金融にテキストマイニングを利用している研究
をここでいくつか取り上げる. Koppel らは金業の株価
のデータを利用して, 企業のニュースが良いニュースな
のか悪いニュースなのかを分類するテキストマイニング
の手法を提案している [Koppel 06|. Low らは *seman-
tic expectation-based knowledge extractiom methoddo-
ogy (SEKE)" というニュースなどのテキストから因果
関係を抽出する手法を提案しており [Low 01],
念に関するシソーラスとして, Wordi
を使用している. Schumaker らは金融
記事をもとに, 株価の予測を行うという
を利用したアプローチで行なって, その有効性を確かめ
た [Schnmaker 09|. さらに, Ito らは *gradient inter-
pretable neural networks (GINN)" という, 金融テキス
トのセンチメントを可視化するニューラルネットを利有
したモデルを提案しており, テキストマイニングにお
いて, 解釈可能性を追求している [lto 1Sb, to 18al.
Miles らは, NISCT EURO index の変動予測(上昇、
下降, 変化なし) の予測を, European Cemtral Bank
(ECB) の発表する文書の文脈から予測する手法を提案
している [Nilee 10|. Xing らは, アメリカの株式市場

人工知能学会研究会資料
SIG-FIN-024

における, 企業間のつながりを株価の変動の特徴に加
えて, テキストマイニングを利用することでより良く
抜き出す手法を利用し,アセットアロケーションタスク
に組み込むことで, 企業問の関係を正確に把握し。 ポー
トフォリオを最適化する王法を提案している [Xing 14|.

次にテキストマイニングを金融の分野に応由している
日本菩をターゲットとした研究について述べる。Salai
らは日本語のニュースのうち。 業績について書かれた文
章の中の内関係を抜き出す手法を提案しており。 ブー
トストラッピング的な手法により。 自動的に因果関係
を抜き出すための因果を示す手がかり表現を抜き出し
ISakai 07|. Sakaji ら    ュユース記事から続計的な手
法により 自動的に江所動向を示す表現を抜き出す手
法を提案した [Sakaji 08|. さらに, Sakaji らは決濾短
信の中から自動的に策な因昌係を抜き出してくる手
法を提案した [Bakuji 17|. Kitauuori らは決算短信の中
から業績に関する文章をニューラルネットワークモデ
ルを利用して取り出し。 分類する半教師あり学習の王
法を提案している [Kitamori 17|、

提案手法は
ける関連銘柄を選ぶというタスク
して, ファンドマネージャーをサポートするための
手法である. 手法朋は図1 の通りである. まず, テー
マの単語をインブットとして入力するとWord2vec を
利用した類似度と企業情報における単語の共直に基づ
いた頻仙度を評算し。 それらを合わせて最終的な清
の類似度を計算する. 単語の類似度を使用して, 元の
テーマの単関連する単話を選び, その単語を含む
文を企業情報の中から抽出する. さらに。 抽出きれた
文章内に含まれる最終的な関連単語の出現回数とその
類似度を加味して企業の須似度を計算する. その結果
づき, 企業の関連度ランキングを作成し,アウト
抽出の根拠文として, 捕出さ
を含む企業情報の文を一緒にア

終的な関連単語
ウトブットする.

3.1 Word2vec モデルの構築とそのモデル
を利用した類似度計算

まず, テーマの単語の入力を受けた後, Word2vec を
利用した疾人単語の拉出と類人度計算を行う. Word2vec
とは, NHikoloy ら [Mikolov 13] によって提案された。 単
語を多次元の分散表現ベクトルに落とし込む手法であ
る. 類似度については, コサイン疾似度を使用して計
算する.
人工知能学会研究会資料
SIG-FIN-024

図 + 手法概要図。例として, 「人工知能」を入力とした時を幸せている. た

[rano 19a] より

Word2vec を利用した類似度計算において, 異なるハ
イバパーバラメーターセットで作成した Word2vec モデ
ルを組み合わせて使用している. これは, Word2vec は
学習が一意に同じ結果を返すわけではなく, かつ,ハ
イバーバパラメーターによって結果に大きくぼらつきが
発生するため。 それらの影響を緩和するために, 異な
るハイバーバラメーターセットを利用して学習させた
モデルをアンサンプルした。 主に, Dimensions, WVord
indow size の異なるパラメーターセットで学習させた。

これらのハイパーパラメーターを使用して学習させ
たモデルを使用して, 尊似度を計算した。 以下、この
類似度を「類似度 Aj」 と呼ぶ 類仙度の詳算方法は
以下の通りである

(wordがNiにおけ

aa る上人度上位p個
Mona ニ        入る場合)     の
9          (⑯

・ word は, 全ての語代の中で番目の単語, 7
は番目の Word2vec モデル, cer。 はテーマの単
語として入力された単語と or の 7 のモデル
おけるコサイン類仏度。 si はword の
おける類似度。 sz は word。 の類似度 A である.
上記で定義された <4。 ga。 の調和平均を取ることで。

し 数値などは実際のものと異なる。

era を計算する.さらに。 sa ag が0である場
合はsaera も 0 となる. つまり, Word2vec のモデ
ルのいずれかにおいて, ord が類似度の上位ヵ個に
入っていないり場合にsaer。 も0 となる.

この一達のアンサンプル的手法は, Nagta らの研究
[Nagata 18] を参考にしているが, 新しく調和平均を取
り入れ, 拡張を行なった

3.2 企業情報内における単語共起を利用し
た類似度計算

本手法において使用している二つの類似度のうちー
つは3.1侵で説明した通り。 Word2vec を使用したもの
であり, もう一つの類似度を本節で説明する.

も う 一つの無人度計算は企業情報内における単語共
起を利用した無似度計算である. Word2wec は文
束を当てた手法であり, そのため。「東京」と「大阪」 が
類似単語として判定されるといった特徴がある. しか

・今回の目的に照らし合わせると, こういった, 同じ
文脈で使用されるが, 関係価の薄い単語が含まれるな
どといったことは望ましいとは言えない。 そこで, 企
業情報内における単語共起を利用した頻似度計算の手
法を新たに提案するとともに, Word2vec と併用するこ

とにした. なお, この手法を利用することで, より下
位の概念が強く取れることは, [Hiruuo 19b| で示して
いる.

企業情報内における単語共起を利用した類似度計算
により計算される類似度 B(sgz』) は次の通り計算
きれる. 図 2は計算の具体例を示している.

ミスターモット、「ATa
ECSrrps3

較 2 舌人度(sgseax ) の計算例。 “TYO: oo は東
京証券引所におけるそれぞれの企業の銘柄コードを示
している.         spn 5ー08。 spo
/6ニ0.6667 と計算される.     らの例はあくまで一
部であり, 実際の結果とは異なる. [Hirano 19a| より.

まず, インターネットを通じてクローリングにより
取得した決算短信 (1R) と企業ウェブサイトから取得
した企業情報を利用し, テーマの単語を企業情報に合
む企業を抽出する. 図 2 の例では, テーマの単語「人
工知能」に対して, 全部で 10 個の企業を抽出できて
いる. (この例はあくまで一部であり, 実際の結果とは
異なる。    で, “TYO: xsoxxY は東京証券取引
おけるそれぞれの企業の銘柄コードを示している. 以
下, このテーマの単語を元に捕出された企業のリスト
を「マスターセット」と呼ぶ。次に, ほぼ同等の操作
を wordh、word5……・ で実施する違いはターゲットと
する単語がテーマの単語ではなく, wor。 にな
である. つまり, worg, を企業情報に含む企業を抽出
していくことになる 図2の例では, worh「自然言語
処理」を含む企業は 5 つである

企業のリストを「テストセット (word)」 と時
にする. 同様にデストセット (org) を全て計算する。
そして, 最終的に sp を次式に徒って計算する。

san
[マスターセット 1n {テストセット (wed
ltテストセット (word

これはほ, テストセット (ord:) のマスターセットト

人工知能学会研究会資料
SIG-FIN-024

する再現率の計算である 例えば, cord「自然言語
理」の場合 5 つの企業がテストセットに含まれ,。 その
うち, 4 つの企業だけがマスターセットにも含まれて
いる. そのため。 spora。 は475ニ0.8 と計算される。
人も同様に計算されるのでsparg。 = 4/6 = 0.6667
となる. (これらの例もあくまで例であり。 実際の結果
とは異なる. )

3.3 最終類似度の計算および最終的な関連
単語の抽出

以上で説明した二つの類似度を使用して, 最終類人
度 ura。 の計算を行う. 最終類似度 Surz。 は単な
る amor。 と ppeora。 の調和平均により計算される。

次に, 最終類似度 がSr を用いて, 最終的な関連
単語の搬出を行う 最終類和度 PSqer。 の上位個の
みを最終的な関連単語とする. 以下の説明においては,
、eord7。を抽出された最終的な関

word or

連単語とする.

3.4 関連銘柄の抽出およびその関連度の計算

eordneord放teord。 に加え, ord。 をテー
マの単語とし, Susr。。。を1 とする. それぞれの企業
の金業情報の中から, wordヵ。 eordュporみ。 それ
ぞれが含まれる文意を抽出し。 それぞれの単語の出現
回数をカウントする. そして 企業のテーマへの関連
度C5 を次式の通り定義する。

日

Cs

771計和         ⑧

ここで, coun。zx。 は, それぞれの企業の企業情報の
中での orの出現回数である. この定義に基づき
各企業のテーマへの関連度が計算され, その関連度
基づいてランキングされる.

4 データと前処理

本章では 本研究において使用したデータと実施し
処理を説明する 本研究においては, 日本語の文
書を使用している第一目標が日本市場をターゲット
としたテーマ弄投資信託の作成をサポボートす」
あったからである 日本語の場合英語などと異なり,
形態素問にス    ングが行われていないため。 形態
素解析を行う必要がある.

1 使用したデータ

おいて, 目的に応じでいくつかのデータを便
用した. 目的は主に二つで, Word2wec の学習用および
企業情報としてである. Word2vec学習用として, ライ
プドアニュースコーバパス!。 Wikipcdhe 日本其記事 (er-
sion 21-Junr2018 22:09) 日本経済新聞 (1990-2015
amd 2017: 2016 年分は技術的問題から使用していない)
を利用した. これらのデータを元に, 1.147.973 調葉,
1.809.736.365 文字を含むテキストデータを Word2vec
の学習に利用した。

企業情報としては, 2012/12/9 一 2018/5/11 の決算
短信, 全 90.813 ファイル (PDE) を日本取引所グルー
プ適時開示情報関覧サービス (TDuet) * より取得し
た企業ウェブサイトのデータとしては, 2018/676
2018/6/25 の期間に, 2.203.460 ファイルのみ (703.699
PDF, 1.472.317 HTML, その他) を取得し
れらの企業情報はインターネットを通じて取得し
た. 本研究においては, これらの多種のデータを組み
合わせることで, 関連銘柄を抽出している。

4.2 実施した前処理

日本藻の文書においては形態素解析が必要である,
日本語形粗解析器として, KyTen [Nenbig 11] や
JUMAN++ [Norita 15] などがあげられる. 本研究に
おいては, もう一種類の MIeCab (yesion 0.996)*!を人
用した, また, MeCab 用の追加の日本語辞書として。
NEologd' を使用した.

1leCub およびNEologd を使用して, 全てのチキスト
データを形態に分遂してから使用している Word2vec
の学習においては。 形態解析して。 形態素間にスペー
データを Word2vec の学習用テキストとし
方 企業情報は検索を早くするために。
形態解六後のテキストを, どの企業の情報なのかや
データのソースなどとともにリレーショナルなデータ
ベースに保存して使用した特に。 収集した企業情報
は 600GB 程度あり, 実験において, リレーショナルな
形で保存されていないと照会が非常に困難であるため,
リレーショナルなデータベースでの保存を採用し

5 実験と結果

本章においては。 本手法のハイパーパラメーターチ
ングと評価実験およびそれらの結果について人

hrtmpa://vww-rondhwit.com/agn1oad.htm13dce|
2httpa//awape-viktmedierorg/auki/eteet/
httme://mwerjpxrco。jp/ednitaes/13ting/tdnet/
Jrtp://tahu910。gsthub。io/mecsb/
*hrpai//gtrhubcom/neo1oga/secab-1padie-neo1oe

人工知能学会研究会資料
SIG-FIN-024

べる-
各節ごとでの説明の前に, 実験で共通で使用してい
る評価用データについて述べる. 評価用データとは, 提
案手法等を使用して出てきた結果を評価するために使っ

たデータである. 評価用に使用したテーマは「美容」 ,
「育児」.「ロポット」,「如楽」の4つである. 経験のある
ファンドマネ    ー 1名のタグ付けデータを使用し

それを元に評価用データを作成したTOPIX500 の中
からランダムに選ばれた 100 銘柄を使用し, タグ付け
を行なってもらった。 タグ付けの基準は同様で。 以下
の通りである

0. 全く関係ない

1. あえて言えば関連している

2. この企業の事業の一部に関係がある
・ この企業の代表的な事業だ

がない場合には, その旨のタ
ダグ付けを行うことができる

表二 ファン     ャーのタグ付けの例、“+* は
銘柄のタグ付けに自信がないことを示す.

FM    FM2
タグ 自信なし | 分類 自信なし
門
エ
エ

還

表1 はファンドマネージャーによるタグ付けの例で
ある. 例えば, 銘柄コード 4544のみらかホールディン
ダグスに対して, ファンドマネージャー1 は自信がない|
ものの. 「あえて言えばぼ関連している」とタグをつけた。
方で, ファンドマネージャー2は「全く関係ない」と
タグをつけた. このファンドマネージャー』名による
タグ付けに工づいて, 評価用データを作成する関連
銘柄の判定は非常に難しいタスクである. (詳細につい
ては [Hirano 19c] を参照 ) そのため, 評価用データ
においては, 1名以上のファンドマネージャーが関連の
ある銘柄だと判断した場合には, 関連銘柄とすること
とした. これは人間が行う以上。 知識不足や見落と
しにより, 関連のない銘柄だと判定してしまう可能性
が充分に存在するからである

そこで, ファンドマネージャーによるタグ付けを詳
価用データに変換する際の最終的な基準を次のように
定めた。

ャーによるタグ付けの評価用データへの変換例。

人工知能学会研究会資料
SIG-FIN-024

^FNI" はファンドマネージャーを。

FM によるタグ付け         評価用データ

銘柄 | FM1 FM2 FMS FM4| 関連銘柄    関連度レーティング

A  1  きす 2  1 | マ    (G+3+2+10/4=1.7500

g | p +  9 0 | マン    (0+1+0+0)/4ニ02500

ce | 0 nd 0 ol     (0+1x05+0+0)735ニ0.1429
p | 3 1G) 9  0      2+lx05+0x05+0)/3ニ08338
E | 0 eo     0G)     (0+0+1x05+0x08)/3ニ0.1667
Fl eo oe     1G)     (0+0+1x05+1x05)/8ニ03333

・自信のないファンドマネージャーを除き, 1名以 5.1 ハイパーパラメーターチューニング

上のファンドマネージャーが関連銘柄だと判定し
た (1.2.3のいずれかにタグ付けした) 場合は関連
銘柄としてみなす.

で名のファンドマネージャーの04 の関連度のタ
ダグ付けを算術平均したものをその銘柄の関連度
レーティングとする. ただし, 自信のないファン
ドマネージャーが存在する場合は, 平均を取る際
にその人の重み付けを 1 ではなく, 0.5 とする.

表2はファンドマネージャーによるタグ付けから評
価用データへの変銘例である. 銘柄 A と Bは典型的な
例である. 全てのファンドマネージャーが銘柄A は関
達銘柄とみなしている. その    価用データにお
いても, 関連銘柄としている 鉛策B も評価用データ
$いては関連銘柄となっている. これは, 1 名のファ
MM  みなしているからで
1ファンドマネ

ドマネー     見 しなどから胃

柄としていない可能性が充分にあると考えられるから
である

方で, 銘柄C は少し異なる. 1 名のファンド
ャーが関連銘柄としているが, そのファンド
ャーは自信がないとしている. このような場
。 評価用データにおいては, 関連銘柄と判定し

らに, 銘柄 D-F はもっと特殊なケースである
いても同様ではあるが, 自信のないファン
ャーは05 名分としてカウントして平均を
とったものを関連度レーティングとしている. さらに。
銘柄選とF においては, 関連銘柄とタグをつけている
ファンドマ        !全員自信がない場合のため, 評
人用データにおいては関連銘柄とは判定していない.

このように基準を定めたものの, 自信がないとタグ

をつけられたデータは 28/1200 = 2.3% しかなく。 実際

デ
2 名以上が自信がないことを示すタグを同

に
マ, 同一銘柄につけた銘柄 DF のようなケースは存在
しなかった

より良いハイバーパラメーターを探すために, ハイ
パーパラメーターチューニングを行なった. 企業情報
のデータソース, 3.1 侵で説明した複数の Word2vec の
モデルをアンサンブルするフェーズにおける上位何財
を取るかという値 (Hyperparameterl という)。33 委
で説明した。 最終類似度の計算における上位何個を取
るかという値 (Hyperparameter2 という) を変更して,
実験をし, その結果からチューニングを行なった。ノ
イバパーバラメーターのチューニングの方式はグリッド
サーチであり, それぞれのバラメーターに対していく
つかの次散的な値を使用して, その全ての組み合わせ
を実験し。その中で良い結果を出したパラメーターセッ
トを使用するという手法である. グリッドサーチで合
用したそれぞれのパラメータに対するグリッドは以下
の通りである

・ 企業情報のデータソース: (1) 決算知信のみを合

(2) 企業ウェブサイトからのデータのみを使

用 3) 潜入短信および企業ウェブサイトからの
データの天方を合用

・ Hyperparameterl: top-10. top-20, top-50, toD-
100.top-200. op-500. top-1000. rop-2000

・ Hyperparamneter2: top-5、 topr10. top-20、 top-
50. top-100、top-200. top-500, top-1000

評価用データとしては, 「美容」, 育児」「ロボット」,
娯楽」があるが, そのうち, 「美容」 ,「育児」,「娯楽」
の三つをハイパーパラメーターのチューニングに利用
し. 残りの一つの「ロポット」を性能評価用に使用し
た.「ロボット」を性能評価用に使用した理由は, 事前
の実験で, 地も低い結果を出していたからである.
ハイパーパラメーターのチューニングに    ては,
結果の良し患しをいちいち人間が判断することは不可
能であり, 何かしらの「良さ」の指標を利用しなけれ|
ばならない. そこで, 本実験においては, FI による

ニングを採用することとした. 結果として, 採
ハイバーパラメーターセットは企業情報のデータ
ソースが決算短信のみ。 hypcrparameterl が top-500。
hyperparmetr2 が top-50 となった。

5.2 テストデータでの性能評価

前委で定めたハイパーパラメーターを採用し, 残っ
ている一つの「ロボット」の詳価用データを使用して。
性能評価を行なった. 比較として, 企業情報として決算
短信のみを使用し.「ロボット」という単語をそれぞれ
の企業情報に単純昭合をすることで企業を捕出すると
いう実験を行なった。 結果は表3, 4. 5 の通りである

表3: 「ロ  ト」の評価用データとチューニング後の
ハイバーバラメーターを使用した場合の提案手法の結
果に対する提則行列
評価用データにおいて
関辻本 非連多柄
関連銘柄 |    思
Mul間     N

表 : 企業情報として決算短信のみを使用して,「ロボッ
ト」という単語をそれぞれの企業情報に単純睦合をす
ることで企業を捕出した場合の結果に対する混同行列
(比較用)

評価用データにおいて
関連銘柄 非関連銘柄

関連銘柄           9                 ョ

ME

表 5i テスト用テーマ「ロポット」における, 提案手
法と比較手法の Precision。 Recall, F1。 Acemmacy. 比
電手法は企業情報として決算生信のみを使用して, 「ロ
ポット」という単誠をそれぞれの企業情報に単純照合
をすることで企業を抽出するという手法である.

Precision Recal Fl Ace

0.8421
01579

提案手法
比較手法

0.5854
0.6499

06906 0.5700
02595 0.4700

表5 を見れば明らかであるが, 表3と4を比べると。
比較手法に比べて, より多くの銘柄を関連銘柄として
抽出しているため, Precision が低下している。 一方で
圧倒的に Recall が向上しており, その結果 F1 も向上

人工知能学会研究会資料
SIG-FIN-024

している. また, 単純な結果の正雄さを滑る Accuracy
も向上しており, 提案手法が良い結果を出しているこ
とがわかる

6 考察

本研究は テーマ関連銘柄の抽出を支援するシステ
ムの構築を目標にしたものであった [Hirano 10c] で示
しているが, これは, 経験のあるファンドマネージャー
にとっても難しいほどのタスクであった.
もそも評価用データがどれだけ正しいのか。 という
については多少の疑問が残る. しかし, 表5 を見る限
りでは, 共本的な手法を利用した比較手法よりは良い
結果を出しており, 提案手法の一定の有効性が示され
たと考えられる

今回の結果は企業ウェブサイトからのデータはなく
ても 決算短信だけでも充分であるという結果になっ
ている. しかしながら, 企業ウェブサイトのデータを
使用した場合には, 一つの単語で抽出できる企業数が
多いこともわかっている. これは。 決算短信だけでな
く, 企業ウェブサイトからのデータも使った
少ない数の関連単語のみを使用すること
連銘柄を抽出していた一方で, 決算短信
接で信用する場合には, より多くの関連単語を採用す
ることで, データの少なさをカバーすることができて|
いるのかもしれない. しかし, 実験で実際に使用した4
つの単語はすでに広く普及している一般的な単語で
あった. そういった一般的単語は決算短信には頻出す
る一方で, 比較的新しい単語は決算短信には出現しに
くい可能性がある. そのため。 今後の課題として。 提
案手法において。 企業ウェブサイトからのデータを使
用しなかった場合に, 比較的新しい単誠においても充
分な柄度を発押するのかを確認しなければならない.

今回の実験における, ハイパーパラメーターのチュー
ダグはある種の教師あり学習のような形のグリッド
サーチで行なった。 教師データとしては, ファンドマ

け正しいかわからないだけでなく, 作成も人手で行う
ため, 時間のかかる作業であり, 多くの評価用データ
を作成するのは困難であった. そのため。 評価に使用

にデータのテーマは限られており, これでは充分な
結果とは言えない可能性もある. もちろん, より正確
で, 多くの評価用データを作成することができれば問
題はないが, 限界がある. さらに, 現在は日本株だけ
を対象にしていたが, これを世界中の株を対象にする
と, 評価用データの作成の釘易度はもっと上がると考
えられる. そのため, 教師なし学習または半教師あり
学習のような手法を作成しなければぼ, どんなテーマに

も対応できるような手法とはならないと考えられる
今後の展望としてだが, 現時点では, 単純に
への関連度のみを考慮してランキングを作成していた
が実際にはもう少し他の地を加えてランキング付け
したいという需要もある. 例えば, テーマにおける代
表性や企業の大きさを加味し    キングが欲しいと
いう意見もファンドマネージャーから聞いた. そのた
め, 様々な指標を取り入れられるようなスキームを作
成することも必要かもしれない. また, 銘柄をテーマ
型投資信託に採用し, 信用を行う際には。ポートフォ
リオ運用をすることになるので, 同じような株価変動
をする銘柄ばかりを組み込むことは望ましくない. そ
れは, 単に価格変動だけではなく, 似たような事業を
行なっている企業を同時に取り込みことは, 結果とし
て, 同じような価格変動を引き起こす可能性を秘めて
いる. そのため, 価格変動や企業情報を主成分分析し
たり, ベクトル化することで, 様々な需要にうまく敵
用できるようにする技術の開発などが必要であると考
える

3

本研究は, 大和証券グループと東京大学大学院工学
系研究科により開設された社会連携講座「次世代運用
テクノロジー」における, 大和証券投資信託委託株式
会社および株式会社大和総研との共同研究の一部であ
り, 大和証券グループの支援を受け, 行われました. 大
和十券グループ各社の多くの方     援をいただきま
した. この場を借りて御礼申し上げます.

参考文献

Mew 9] ReHbam. で』 Wonder Az eronic sriodl
Deloese The MIT Ps (1996)

上remo 1 Hhremo. NL。Sakaii是、Kimere。 S。 izumi K、 Ne
suelima、 HH。Nagno. Sand Kato、 Secction of Related
oks vsing Finmnrinl Text Nining im Proceeings g7 18
超B Jarermerionel Coryewencr の のafe Afimang Worksope
(CPMWWり, pp 191-198, Singapore。 Singapore (2018)

ikawo 19x] Fano。NI: Ezpecnon o/ Relcted Stocks 7
77hemed Avtwat fds wwing 7czg Mining Grwduation theo
中The Universicy of Tokoy (2019)

(Hiramo 19bj Thrano、 MI Saleil 本、Kimwra 8。 izumi
atewshiman HH。Nageo- 9. sndl Karo。 ん: 文書内における|
間語の共走を利用した上位天人の負.衣香学会25
四和次大会、pp. 897-G00. Nagowa Aichi Japan (2019), The
Amwociwtion lor Natural Lngnmge Proceesing

ramo 19d| Hrsno。 NL。 Salji。 Kim. S。 gumi K
Niatemshim。 日Nageo. Sr Kato、入Hirano. ML。Sakaji
Kimur。 SIzumi、K。 NMaraushina。 日。 NagAo。 S。 an
Kato. A: Related Stocls Selection witb Dats Colliboratiom
CSima Toxt Niningr 7aformretion。 Vol 10. No. 3 (2019)

Pe ts] lto.T。Sakaii HL。 zemi KTambonchi Kand Ya
mmmhita。 年GINN: gradhent interpnetable neuml nehorks

fr viswalzimg fimanisl tcxts。 7mMeretooncf Jowrwgt of gin
Seiemce end alytice ppx 1-15 (2019)

人工知能学会研究会資料
SIG-FIN-024

[Re sb ho. Salaj 世。 Tamwbonhi。K。 izwmi K and
Yamashita。 Text-Viswalizmng Nenral Nehwork Nodel
dierstanwiing Onltne Financinl in Porzediwgs o/ (ke 99
acsfc-4aie Conyncz on moedge のacoery md ao
Jiang (P4KDD 2078) pp 247-259。 Melbourme. Astral
(009

Ramori 17| Kitsmori。 S。 Selat。 時。 amd Sakait。 HExdrme-
On or aemtemees coneeritmg blstneea perfonmuenee forecest
md cconomic oreast from nmmmaries oF Rnnncial state-
Tnente by deep learming。 in Pioreedings 0/ 2077 /Eどが 5
yowiemn Scme on Coruyaredionf 7viclggoroc (7おだ 93C7
0972. pp 67-73. Honciulu。 ltawaii USA (2017)

[Koppel 06 Koppel。 Ni amd Shtrmmber 1: Good News on
Bad News? Let the Narket Decider im ormmuting 0hlede
4 4fct we ea 7かeory nd 4pptienGo6。 DD。 207-301
Sprineer Ncherands (2006)

Eow 0] Low。 B-T。 Chem、K。 Choi。 L-L。 Chim。 RI-Y and
NE        hc cxpectationrbewedl cmgation knowiclge
Straction: A sedy on Iiong Kong stock monment am
3 im Pcyic4sie Coference on Kowd9e Doowery od
ee Mewg (PDD 2007) pp 1-123 (2001)

[ntolev 13| ioloy、了エ。 Chem K。 Comado。 Grand Demn。
BIHdient Estimation of Word Repreeetatioms im Veetor
Jroceedings 7 (Ac niergonar Oorerence on
に12。 Seohte-

Space
eoyyig Repyrcndefions (7CZE 2079)。 pp
der Amona USA (2013)

[Nmka | Nidew V。 Share NNI。Almeida。 R_ 7。 Ke
rmak せ、snd Fsincar F』 Prediction or the NISCT EURO
iodex basedl on hugzy frammar fraghmnte cxtracted foml
Buropcan Cemtmml Bank statements。 in 2070 mmmetongl
oference of So Cormpwing nd Pfierx fecognifion。 PD.
231-236 (2010)

Meate 1 Menter HH Kawsbaee。 D。 amd Reeli き
LMorphological Amelysis for Unsegrmenred Languagee teing
Recmrremt Newral Network Language Model、 im Procerdimgs
ダ he 2003 Corerce on gpireal Acfiods gn Yatvrol
Zengwage Pcewsrmg (647WLP 97 pp。 2292-2207、L-
bon Ponwgel (2015)

[Newts 1 Nageta。 R。 Nishite Sawd Ototake。 HH: A
NMethod for Dectimg Oversenermlized Be-Verb baxcd on
Sebieetcompiiment Identicstion [pblihet in Japanesel
7かc 32md 4mawel Com/eryce o/ 人ke 7apeee 5octefy ルル
44rafcrgl seeitgencm。 2079 (S47 2073) (2019)

INewbi Ii] Newbig G。 Nakte。 Yamd No 8。 Pomtwise
Prediction or Robust Adaptsbie Japanese Miorphological
Amlyei in Proeeedsmgs o/ 0he 74985 Hmnwet Meettng g7 he
445wociedion 7pr Corwpwdediongi とmatstcxr ガfammor ana
age 7eckmofogie (4C/ 7 29074 pp 520-533 Porm
1 Oreeonr USA (2011)

Selat 07| Smli、 HL amd Nmwmyama、 S: Extraetion of Canwe
jonmntion fiom Newsaer ArtIHa Conrerming Blainee
Perormance。 in /rmrcedtngs g7 (Ac 人94 7F7P Concrmce
2 4reKcigf 7xieikgence 44pplca4ions frmowofions (74
20027. pb. 205-212 (2007)

Beleji SI Sakajk Selai。H。snd Maswwama。S。 Auto-
matic Bxtraetion oh Baai ExBrreaions That Inthcare Eco
jomic Temds、 in racwfcc4ra Conference on fmowUcte
eeey cnd Das Mining (P4KDD 2008 pp. 977-984
(0

Seii 17| Sakaii Hinreno。 R。 Seki HBenmett。 Jand

K: Dieeovery or Rene Cateal Kiowiedgc ront Fi
itemment Summariew in 7he 207 JEなど Symposian on
oymtaieonei Jarelk2ence for Ftmancof おgioeeyng od

Eonomcs /C7F5r 2077) pp 602-608 (3017)

Erhemaker 09] Schemaker。R_ Psnd Chen。H: Textual Aa
xss oh Stock Mrket Prediction Uing Breaking Finanril
Noe The AZFin Thawt System。 4C7 人rsacfiors on 7n-
7maemon Sewue Vol 27. No 2. pp 12:1-12:19 (2009)

Ring 1 Xing. F。Cambria。 Esnd Welch。 RE: Crow
img Semautic View or Robuat Asset ANocwtion (2015)
Itpe://er com/alatracl二3275132

